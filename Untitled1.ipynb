{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nh1e5Bb9Nd9",
        "outputId": "25d9e2af-bb31-4e31-fce9-8bce6e784c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# Install Required Libraries\n",
        "# =============================\n",
        "!pip install -q torch torchvision torchaudio transformers datasets scikit-learn librosa\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import torchaudio.transforms as transforms\n",
        "import librosa\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModel, AutoFeatureExtractor\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# =============================\n",
        "# Step 1: Download & Extract Dataset\n",
        "# =============================\n",
        "dataset_url = \"https://datashare.ed.ac.uk/bitstream/handle/10283/3336/LA.zip?sequence=3&isAllowed=y\"\n",
        "zip_filename = \"ASVspoof2019_LA.zip\"\n",
        "dataset_dir = \"/content/ASVspoof2019_LA\"\n",
        "\n",
        "# Download dataset\n",
        "print(\"Downloading dataset...\")\n",
        "response = requests.get(dataset_url, stream=True)\n",
        "with open(zip_filename, \"wb\") as file:\n",
        "    for chunk in response.iter_content(chunk_size=1024):\n",
        "        if chunk:\n",
        "            file.write(chunk)\n",
        "\n",
        "print(\"Dataset downloaded successfully!\")\n",
        "\n",
        "# Extract the zip file\n",
        "print(\"Extracting dataset...\")\n",
        "with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(dataset_dir)\n",
        "\n",
        "print(\"Dataset extracted successfully!\")\n",
        "\n",
        "# Define paths\n",
        "train_audio_path = os.path.join(dataset_dir, \"LA\", \"train\", \"flac\")\n",
        "dev_audio_path = os.path.join(dataset_dir, \"LA\", \"dev\", \"flac\")\n",
        "\n",
        "# Define protocol file paths\n",
        "train_protocol_file = os.path.join(dataset_dir, \"LA\", \"ASVspoof2019.LA.cm.train.trn.txt\")\n",
        "dev_protocol_file = os.path.join(dataset_dir, \"LA\", \"ASVspoof2019.LA.cm.dev.trl.txt\")\n",
        "\n",
        "# =============================\n",
        "# Step 2: Load Audio Files and Labels\n",
        "# =============================\n",
        "def load_dataset(audio_path, protocol_file):\n",
        "    audio_files, labels = [], []\n",
        "    with open(protocol_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            file_name, label = parts[1], 1 if parts[-1] == 'spoof' else 0  # Spoof = 1, Genuine = 0\n",
        "            file_path = os.path.join(audio_path, file_name + \".flac\")\n",
        "            if os.path.exists(file_path):\n",
        "                audio_files.append(file_path)\n",
        "                labels.append(label)\n",
        "    return audio_files, labels\n",
        "\n",
        "# Load train & dev datasets\n",
        "train_files, train_labels = load_dataset(train_audio_path, train_protocol_file)\n",
        "dev_files, dev_labels = load_dataset(dev_audio_path, dev_protocol_file)\n",
        "\n",
        "print(f\"Loaded {len(train_files)} training samples and {len(dev_files)} development samples.\")\n",
        "\n",
        "# =============================\n",
        "# Step 3: Load Pre-trained Wav2Vec2 Model\n",
        "# =============================\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "ssl_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Freeze the SSL model's parameters (only use it as a feature extractor)\n",
        "for param in ssl_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# =============================\n",
        "# Step 4: Extract Embeddings from Audio\n",
        "# =============================\n",
        "def extract_embedding(file_path):\n",
        "    # Load audio\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # Convert sample rate if necessary\n",
        "    if sample_rate != 16000:\n",
        "        resample = transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "        waveform = resample(waveform)\n",
        "\n",
        "    # Extract features\n",
        "    input_values = feature_extractor(waveform.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
        "    with torch.no_grad():\n",
        "        embeddings = ssl_model(input_values).last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.cpu().numpy().squeeze()\n",
        "\n",
        "# Extract embeddings for all audio files\n",
        "def extract_embeddings(audio_files):\n",
        "    embeddings = []\n",
        "    for file in tqdm(audio_files, desc=\"Extracting features\"):\n",
        "        embeddings.append(extract_embedding(file))\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# Generate embeddings for train & dev sets\n",
        "train_embeddings = extract_embeddings(train_files)\n",
        "dev_embeddings = extract_embeddings(dev_files)\n",
        "\n",
        "# =============================\n",
        "# Step 5: Convert to Tensors\n",
        "# =============================\n",
        "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32)\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
        "dev_embeddings_tensor = torch.tensor(dev_embeddings, dtype=torch.float32)\n",
        "dev_labels_tensor = torch.tensor(dev_labels, dtype=torch.long)\n",
        "\n",
        "# =============================\n",
        "# Step 6: Define a Simple Classifier\n",
        "# =============================\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(SimpleClassifier, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Define model\n",
        "embedding_dim = ssl_model.config.hidden_size  # Wav2Vec2 hidden size\n",
        "classifier = SimpleClassifier(embedding_dim, 2)  # Binary classification (Genuine vs. Spoofed)\n",
        "\n",
        "# =============================\n",
        "# Step 7: Train the Model\n",
        "# =============================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(train_embeddings_tensor, train_labels_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    classifier.train()\n",
        "    total_loss = 0\n",
        "    for batch_embeddings, batch_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(batch_embeddings)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# =============================\n",
        "# Step 8: Evaluate the Model\n",
        "# =============================\n",
        "classifier.eval()\n",
        "with torch.no_grad():\n",
        "    dev_outputs = classifier(dev_embeddings_tensor)\n",
        "    _, predicted = torch.max(dev_outputs, 1)\n",
        "    accuracy = accuracy_score(dev_labels_tensor.cpu().numpy(), predicted.cpu().numpy())\n",
        "    print(f\"\\nDevelopment Set Accuracy: {accuracy:.4f}\")\n",
        "    print(classification_report(dev_labels_tensor.cpu().numpy(), predicted.cpu().numpy()))\n"
      ]
    }
  ]
}